<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>LogicForeach</title><meta description="刘之帅的个人博客"><meta property="og:type" content="blog"><meta property="og:title" content="LogicForeach"><meta property="og:url" content="logicforeach.github.io"><meta property="og:site_name" content="LogicForeach"><meta property="og:description" content="刘之帅的个人博客"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="刘之帅"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/LOGO.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"logicforeach.github.io"},"headline":"LogicForeach","image":["/img/og_image.png"],"author":{"@type":"Person","name":"刘之帅"},"description":"刘之帅的个人博客"}</script><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/LOGO.jpg" alt="LogicForeach" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">主页</a><a class="navbar-item" href="/archives">文章</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">与我相关</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/LogicForeach"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-16T05:05:31.258Z" title="2020-04-16T05:05:31.258Z">2020-04-16</time><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">10 分钟 读完 (大约 1478 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/16/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%A4%9A%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84reshape/">直观理解多维张量的reshape</a></h1><div class="content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在机器学习领域，通常把标量、向量、矩阵，都称为张量，即将张量分为：</p>
<ul>
<li>0 维张量，标量</li>
<li>1 维张量，向量</li>
<li>2 维张量，矩阵</li>
<li>….</li>
<li>n 维张量</li>
</ul>
<p>标量很好表示，就是一个数：</p>
<script type="math/tex; mode=display">
1</script><p>向量是一组数：</p>
<script type="math/tex; mode=display">
(1,2,3)</script><p>矩阵是一组向量</p>
<script type="math/tex; mode=display">
((1,2,3),(4,5,6))</script><p>同时也可以把矩阵表示成类似表格的形式</p>
<script type="math/tex; mode=display">
\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}</script><p>3 维张量可以表示为一组矩阵</p>
<script type="math/tex; mode=display">
(((1,2,3),(4,5,6)),((7,8,9),(10,11,12)))</script><p>这样看上去不是很直观，但当维度大于 2 以后，也无法用表格直观表示了，这里我推荐使用树状表示法</p>
<p><img src="/2020/04/16/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%A4%9A%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84reshape/幻灯片1.PNG" alt></p>
<p>树状表示法的每一个分支代表一个索引，最后一列的圆圈代表张量中每个分量，其后紧接的方块是分量的数值，例如整数 12 被存储于 <code>Tensor[1][1][2]</code> （索引从 0 开始）</p>
<p>几乎所有机器学习框架，都会给张量分配一个名为 <code>shape</code> 的属性，该属性直译为形状，表示张量每个维度的“长度”，如上面的这个张量的<code>shape=(2,2,3)</code> 每个维度的“长度”决定了最大索引号是多少，如第一维的长度 2 ，则第一维度的最大索引号只能到 1，同时分量个数等于各维度长度之积，如上图张量中的分量数目为 <code>2*2*3=12</code></p>
<p>伴随着 <code>shape</code> 属性的出现，随之而来的就是 <code>reshape</code> 方法，<code>reshape</code> 方法可以改变一个张量维度数目和维度长度。</p>
<p>但是张量维度也不是想怎么改变就怎么改变的，不论你是几维张量，在数据结构上，说到底也不过是一个多维数组，多维数组本身就是一个逻辑结构，实际在内存中，它其实是一个元素接一个元素的线性储存的，所以原则上，无论一个张量 <code>shape</code> 怎么改变，它的分量个数都是不变的，而且它的分量在内存中的存储顺序也是不变的。</p></div><a class="article-more button is-small size-small" href="/2020/04/16/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%A4%9A%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84reshape/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-14T07:44:30.084Z" title="2020-04-14T07:44:30.084Z">2020-04-14</time><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">12 分钟 读完 (大约 1754 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">目标检测中的损失函数笔记整理(待续)</a></h1><div class="content"><h2 id="Smooth-L1-Loss"><a href="#Smooth-L1-Loss" class="headerlink" title="Smooth L1 Loss"></a>Smooth L1 Loss</h2><h3 id="函数定义与性质："><a href="#函数定义与性质：" class="headerlink" title="函数定义与性质："></a>函数定义与性质：</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><script type="math/tex; mode=display">
smoothL1(x) = \left\{ \begin{aligned} 0.5x^{2}    \qquad if \left| x \right| < 1\\ \left| x \right| - 0.5  \qquad otherswise,  \\ \end{aligned} \right.</script><h4 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h4><ul>
<li>连续函数，在 x=±1 处连续</li>
<li>偶函数，关于 x=0 对称</li>
<li>x=0 处取唯一极小值 0</li>
</ul>
<h3 id="导数定义与性质："><a href="#导数定义与性质：" class="headerlink" title="导数定义与性质："></a>导数定义与性质：</h3><h4 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h4><script type="math/tex; mode=display">
\frac{d[smoothL1(x)]}{x}= \left\{ \begin{aligned} x \qquad if \left| x \right| <1\\ \pm1  \qquad otherswise,  \\ \end{aligned} \right.</script><h4 id="性质-1"><a href="#性质-1" class="headerlink" title="性质"></a>性质</h4><ul>
<li>导函数连续</li>
<li>在 x 较小时，对 x 的梯度也会变小，而在 x 很大时，对 x 的梯度为 1 ，总之 x 梯度绝对值最大为 1 </li>
</ul>
<h3 id="来源："><a href="#来源：" class="headerlink" title="来源："></a>来源：</h3><p>在 Faster RCNN 用于对 （x，y，w，h）进行回归：</p>
<script type="math/tex; mode=display">
L_{reg}(t_i,t_i^*)=smoothL1(t_i-t_i^*)
\\t_i=(x_i,y_i,w_i,h_i)
\\t_i^*=(x_i^*,y_i^*,w_i^*,h_i^*)</script><h3 id="优缺点分析："><a href="#优缺点分析：" class="headerlink" title="优缺点分析："></a>优缺点分析：</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>相较于平方误差， Smooth L1 Loss 的在预测值与标签值相差较大时，梯度被稳定为 1，这样不会让那些少量离群点贡献较大的梯度，令整个梯度下降方向，向那些错误的点倾斜。</li>
<li>相较于绝对值误差，Smooth L1 Loss 在 0 点处可导，且预测值与真实值相差的越小，梯度也越小，这将有利于模型收敛</li>
<li>…..（待补充）</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>在目标识别时，（x，y，w，h）的回归损失采用加和方式组合在一起，使得（x，y，w，h）的损失彼此独立，导致 loss 虽然看起来不错，但是（x，y，w，h）四项的回归损失有高有低，这种情况下的结果通常最终效果的评价都不是很好（最终效果的评价采用 IOU 作为标准）。</li>
<li>目标识别时，使用 Smooth L1 Loss 的话，大边框的 loss 和小边框的 loss 并不能同等比较，相同 loss 值的情况下，大边框（100*100）的宽和高差2个像素点，肯定比小边框（10*10）的宽和高差2个像素点效果要好，但是 Smooth L1 Loss 中没有考虑边框大小这个问题，在 YOLO 中，作者使用平方根函数缓解这个问题，可这个问题依旧存在。换句话说就是  Smooth L1 Loss 不具有尺度不变形</li>
</ul></div><a class="article-more button is-small size-small" href="/2020/04/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-05T14:03:31.957Z" title="2020-04-05T14:03:31.957Z">2020-04-05</time><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%B0%88/">机器学习杂谈</a></span><span class="level-item">14 分钟 读完 (大约 2062 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/05/%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E7%9A%84%E7%90%86%E8%A7%A3/">关于矩阵求导的理解</a></h1><div class="content"><h2 id="矩阵微分"><a href="#矩阵微分" class="headerlink" title="矩阵微分"></a>矩阵微分</h2><blockquote>
<p>为了书写方便，常把单个函数对多个变量或者多元函数对单个变量的偏导数写成向量或者矩阵的形式，使其可以当做一个整体处理。矩阵微积分是多元微积分的一种表达方式，即可以使用矩阵和向量来表示因变量每个成分关于自变量每个成分的偏导数。 ——《神经网络与深度学习》</p>
</blockquote>
<p>对这句话的理解：</p>
<ol>
<li><p>矩阵微分是多元函数求导的一种书写行书，它的结果是各个偏导数的按照某一规定的布局。</p>
</li>
<li><p>矩阵微分的结果是一个矩阵或者向量，它内部一定包含 <strong>因变量里每一个成分关于自变量里每一个分量的偏导数</strong> ，即</p>
<script type="math/tex; mode=display">
 \frac{\partial{\pmb{Y}}}{\partial{\pmb{X}}}=
  \left[
  \begin{matrix}
     &  &  \\
     & \frac{\partial y_i}{\partial x_j} &  \\
    &  & 
   \end{matrix}
   \right]\\
   y_i\in\pmb{Y},x_j\in\pmb{X}</script></li>
<li><p>这里的 $\frac{\partial y_i}{\partial x_j}$ 是一个代表元素， 下标 $i$ 和 $j$ 也可以理解为在分母布局下的第 $i$ 行、第 $j$ 列 ; 在分子布局下的第 $i$ 列、第 $j$ 行，关于分子布局分母布局见下面。</p>
</li>
</ol></div><a class="article-more button is-small size-small" href="/2020/04/05/%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E7%9A%84%E7%90%86%E8%A7%A3/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-05T13:53:29.833Z" title="2020-04-05T13:53:29.833Z">2020-04-05</time><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">10 分钟 读完 (大约 1545 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83/">机器学习中的“分布”</a></h1><div class="content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>从在输入空间中的一个具体的实例上抽出一些属性，将这些属性组成一组向量，这组向量被称为特征向量。当一个特征向量输入到“学习器”中，“学习器”可以依据输入的特征向量返还一个期望的结果。用通俗的话讲，可以将“学习器”视为一个函数，建立一个输入空间到输出空间的映射，映射规则是由不断训练建立起来的。</p>
<p>一个特征向量所期望的结果，被称为标签。在学习器的训练阶段，我们将特征向量与该特征向量对应的标签一同输入到学习器内，学习器根据自身输出与期望输出的“距离”进行自我优化，不断缩小输出与期望的差距。</p>
<p>考虑到学习器的泛化问题，我们并不要求学习器的输出与期望完全一致，通常我们设立一个相对较“软”的指标。比如对于分类任务而言，我们并不要求学习器输出具体的类别，而是要求学习器输出该特征向量所描述的实例属于某个类的概率是多少；对于回归任务而言，我们期望输出值与期望值尽可能的接近而非完全相同。</p>
<p>习惯上讲特征向量组成的空间称为“特征空间”，也叫”样本空间“，所以特征向量又称为“样本”。在西瓜书中写道：</p>
<blockquote>
<p>通常假设样本空间中全体样本服从一个未知的“分布”（distribution），我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”（independent and identically distributed，简称 i.i.d.） ——《机器学习》 周志华</p>
</blockquote>
<p>那么问题来了，什么叫分布？什么叫独立同分布？为什么要这样假设？</p>
<p>本文即是我个人对机器学习中“分布”的理解。</p>
<h2 id="什么叫分布？"><a href="#什么叫分布？" class="headerlink" title="什么叫分布？"></a>什么叫分布？</h2><p>我试图从概率分布对分布进行理解，要理解概率分布，先要搞清楚一个名词——随机变量</p>
<h3 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h3><blockquote>
<p>随机变量（random variable）表示随机试验各种结果的实值单值函数。随机事件不论与数量是否直接有关，都可以数量化，即都能用数量化的方式表达。  </p>
<p>随机事件数量化的好处是可以用数学分析的方法来研究随机现象。例如某一时间内公共汽车站等车乘客人数，电话交换台在一定时间内收到的呼叫次数，灯泡的寿命等等，都是随机变量的实例。</p>
</blockquote>
<p>简单来说，随机变量就是把事件抽象为一个数值，这个数值可以是事件的结果、事件的编号、事件的属性等。同一个事件，从不同角度进行抽象，将得到不同的随机变量。比如“一枚灯泡的寿命”，如果从单枚灯泡的角度进行抽象，那么寿命可以为 1年，2年，10年，这里 1 2 10 就是一组随机变量，如果从不同类型的灯泡角度抽象，1号灯泡寿命到达10年，2号灯泡寿命到达10，4号灯泡寿命到达10年，这里的 1 2 4 又是一组随机变量，这两组随机变量因为意义不同，所以是不能放在一起讨论的，所以只有相同意义的随机变量才能放在一起讨论，下面概率分布中所提及的随机变量，都是指意义相同的随机变量。</p>
<h3 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h3><p>概率分布，是指用于表述随机变量取值的概率规律。将随机变量作为横轴，概率作为纵轴，把随机变量与对应变量画上去，构成一个图形，这个图像就是概率分布的直观表示。通常也用概率分布函数表示 $F(x)$ 来描述一个概率分布，概率分布函数被定义为：</p>
<script type="math/tex; mode=display">
F(x)=P\{X<x\}</script><p>总之概率分布也可以理解为一个函数，它刻画了随机变量与概率的映射关系，给定一个概率分布，就可以求任何随机变量对应的概率了。当一个随机变量与它的概率满足某一个概率分布的映射关系时，则称这个随机变量服从该概率分布。</p>
<h3 id="机器学习中的-“分布”-是概率分布吗？"><a href="#机器学习中的-“分布”-是概率分布吗？" class="headerlink" title="机器学习中的 “分布” 是概率分布吗？"></a>机器学习中的 “分布” 是概率分布吗？</h3><p>前文西瓜书中所提及的分布，即为概率分布，指每个样本从样本空间中被抽到的概率遵循统一的概率分布。为了说明，假设一个样本空间的抽样服从以下概率分布：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">$\pmb X$</th>
<th style="text-align:center">猫</th>
<th style="text-align:center">狗</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>P</strong></td>
<td style="text-align:center">0.5</td>
<td style="text-align:center">0.5</td>
</tr>
</tbody>
</table>
</div>
<p>这里的 $\pmb X$ 是表示从样本空间的任抽取一例所得结果的随机变量，可取 { 猫，狗 } ；<strong>P</strong> 是随机变量对应的概率。</p>
<p>假设样本空间的随机变量  $\pmb X$ 服从上述概率分布，从样本空间中独立地、按照上述分布地进行抽样，最终得到得到 n 个样本 $(\pmb X_1,\pmb X_2,\dots,\pmb X_n)$ , 其中 $\pmb X_i$ 是相互独立且均与 $\pmb X$ 服从同一概率分布的随机变量，所以 $\pmb X_i$ 的取值范围和每个取值对应的概率都与 $\pmb X$ 相同。</p>
<p>也就是说在独立同分布的假设下，每个样本取到猫还是取到狗的概率都各占 0.5 ，随着样本数目的增多，在所有样本中任取一个样本是猫是狗的概率分布也将趋近于总体的概率分布，如此而来，虽然样本数目远不及总体，但可以尽可能全面地表现总体的特征，这便是独立同分布的意义。</p>
<h3 id="如何理解-“分布”-的概念"><a href="#如何理解-“分布”-的概念" class="headerlink" title="如何理解 “分布” 的概念"></a>如何理解 “分布” 的概念</h3><p>将随机变量的取值与其对于的概率，画在随机变量为横轴、概率为纵轴的直角坐标系上，所有点构成的图像，即为概率分布的一个直观形象。也可以说，概率分布就是指这个图像。在直角坐标系上的一个图像，又对应着横轴与纵轴的一种映射关系，所以也可以说，概率分布是随机变量与概率的映射关系。那么什么是 “分布” 呢，<strong>“分布” 即是一个描述直角坐标系上图像的词，一个描述映射关系的词</strong>。如：频数分布，其实是在描述随机变量与频数的映射，XX分布，就是描述某一变量与XX的映射。总结一下就是：<strong>分布即图像、分布即映射</strong> 。</p>
<p>首先需要理解，什么是叫独立，什么叫同分布。</p>
<p>独立好理解，就是指一个特征向量的结果不影响另外一个特征向量，</p>
<p>同分布按照我的理解就是指所有特征向量与其期望的输出都具有相同的映射关系，即这个映射关系在这个样本集唯一。</p>
<p><strong>为什么要求独立呢？</strong></p>
<p>想想也是，我们最终学得的一个“学习器”，这个“学习器”被定义为一个特征向量与模型输出的映射关系，如果一个特征向量的结果，受到另一个特征向量的影响，此时两个特征向量不独立，如果我们想得到一个正确的输出需要把两个特征向量都输入进去，否则学习器会困惑，具体一点的例子就是，把一张只有猫尾巴的图片作为训练素材输入给一个“猫狗分类的学习器”进行训练，最后学习器肯定得不到一个好结果。</p>
<p><strong>为什么要求同分布呢？</strong></p>
<p>也是这个道理，大多数“学习器”只能在大量训练中，学会一种映射关系，比如猫狗分类任务，”学习器“的输出非猫即狗，这时候混几张兔子的素材进去，“学习器”准确度肯定要下降，此时对于猫狗素材而言，它的特征向量与期望输出存在一种映射关系，对于兔子素材而言，它的特征向量与期望输出存在的映射关系，一定与猫狗素材的不同，此时训练集的样本就没有满足同分布。</p>
<p>所以一个优质的训练集，样本独立同分布是一个必不可少的前提，如果样本不独立，那么学习器学不到完整的特征，如果样本不同分布，则学习会在不同映射规则之中跳来跳去。独立同分布少了哪个都会让学习器变的不稳定。</p>
<h2 id="BN-论文中所提及的-“分布”"><a href="#BN-论文中所提及的-“分布”" class="headerlink" title="BN 论文中所提及的 “分布”"></a>BN 论文中所提及的 “分布”</h2><p>“分布” 这个词另一个提出场景，就是在 BN 解决 ICS 的时候，</p>
<blockquote>
<p>在文章<a href="https://arxiv.org/abs/1502.03167">Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>中，其对BN与ICS是这样解释的：由于前一层的参数更新，所以这一层的输入（前一层的输出）的分布会发生变化，这种现象被称之为ICS。同样，这篇文章的观点认为BN  work的真正原因，在与其将数据的分布都归一化到均值为0，方差为1的分布上去。因此，每一层的输入（上一层输出经过BN后）分布的稳定性都提高了，故而整体减小了网络的ICS。</p>
<p>原文：<a href="https://zhuanlan.zhihu.com/p/52749286">https://zhuanlan.zhihu.com/p/52749286</a></p>
</blockquote>
<p>这里的分布听上去也不像概率分布，更像最大最小值区间，所以可以理解为一个特征向量到特征向量所在区间的映射，神经网络的映射规则是由特征向量与一组参数的组合运算实现，总会有一些神经元对特征向量的变化很敏感，如果期望输出不变，特征向量所在区间发送了较大的改变，说明特征向量数值波动较大，那么这些神经元可能无法很好的拟合这个映射规则，所以要通过 BN 把所有特征向量都固定在一个相对集中的区间。</p>
<p>顺嘴一起提，已有论文证明，BN 其实与 ICS 无关，参考链接：</p>
<p><a href="https://zhuanlan.zhihu.com/p/52749286">https://zhuanlan.zhihu.com/p/52749286</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-04T11:00:09.966Z" title="2020-04-04T11:00:09.966Z">2020-04-04</time><span class="level-item"><a class="link-muted" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 源码分析</a></span><span class="level-item">34 分钟 读完 (大约 5146 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/04/YOLO3%20%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 参数学习 Keras源码分析</a></h1><div class="content"><h2 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>Keras 源码中的损失函数：</p>
<script type="math/tex; mode=display">
loss(object)=-\sum_{i=0}^{K\times K}\sum_{j=0}^M I_{ij}^{obj} \cdot (2-w_i\times h_i) \cdot [\hat x_ilog(x_i)+(1-\hat x_i)log(1-x_i)]-\\ 
\sum_{i=0}^{K\times K}\sum_{j=0}^M I_{ij}^{obj} \cdot (2-w_i\times h_i) \cdot [\hat y_ilog(y_i)+(1-\hat y_i)log(1-y_i)]+\\ 
0.5 \cdot \sum_{i=0}^{K\times K}\sum_{j=0}^M I_{ij}^{obj} \cdot (2-w_i\times h_i) \cdot [(w_i-\hat w_i)^2+(h_i-\hat h_i)^2]-\\
\sum_{i=0}^{K\times K}\sum_{j=0}^M I_{ij}^{obj} \cdot [\hat C_ilog(C_i)+(1-\hat C_i)log(1-C_i)]-\\
\sum_{i=0}^{K\times K}\sum_{j=0}^M I_{ij}^{noobj} \cdot [\hat C_ilog(C_i)+(1-\hat C_i)log(1-C_i)]-\\
\sum_{i=0}^{K\times K}\sum_{j=0}^M \sum_{c \in classes} I_{ij}^{obj} \cdot [\hat p_i(c)log(p_i(c))+(1-\hat p_i(c))log(1-(p_i(c))]\\</script><p>$K \times K$ 是网格数目，$M$ 是每个网格锚框数目，$I_{ij}^{obj}$ 表示 <code>i</code> 号 网格中 <code>j</code> 号锚框是否负责物体，所谓负责物体就是指是否有物体的中心落到这个锚框，如果有物体就落入则值，没物体落入则值为0。$w_i,h_i,x_i,y_i$ 表示网络预测的盒子长宽和中心位置，戴帽子的表示的是真实的长宽和中心位置。$C_i$ 是网络的预测的置信度，带帽是真实置信度。$p_i(c)$ 表示类别为 <code>c</code> 的概率，带帽表示真实概率。</p></div><a class="article-more button is-small size-small" href="/2020/04/04/YOLO3%20%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-04T11:00:08.849Z" title="2020-04-04T11:00:08.849Z">2020-04-04</time><span class="level-item"><a class="link-muted" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 源码分析</a></span><span class="level-item">28 分钟 读完 (大约 4264 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/04/YOLO3%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 网络结构 Keras源码分析</a></h1><div class="content"><p>YOLO3 Keras 源码：<a href="https://github.com/qqwweee/keras-yolo3">https://github.com/qqwweee/keras-yolo3</a></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><h3 id="网络结构图"><a href="#网络结构图" class="headerlink" title="网络结构图"></a>网络结构图</h3><p><img src="/2020/04/04/YOLO3%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/2018100917221176.jpg" alt="img"></p>
<p>图片来自：<a href="https://blog.csdn.net/leviopku/article/details/82660381">https://blog.csdn.net/leviopku/article/details/82660381</a></p>
<p>将 YOLO3 网络结构划分为多个层和层包，下面的各个层包的解释：</p>
<ul>
<li>conv：卷积层</li>
<li>DBL： Darknetconv2d_BN_Leaky，conv  + BN + Leaky relu。</li>
</ul>
<ul>
<li>res*：resblock_body， * 是数字，表示内含res_unit数目，有res1，res2, … ,res8等等</li>
<li>res_unit ： 借鉴残差网络思想，将特征值 $\pmb x$ 与经过两个 DBL 的净输入值 $\pmb z$ 相加作为最终净输入。</li>
</ul>
<p>操作：</p>
<ul>
<li>concat：张量拼接，即<code>tf.concat</code>，会使最后一个维度变长。</li>
</ul></div><a class="article-more button is-small size-small" href="/2020/04/04/YOLO3%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-04T11:00:08.811Z" title="2020-04-04T11:00:08.811Z">2020-04-04</time><span class="level-item"><a class="link-muted" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 源码分析</a></span><span class="level-item">1 小时 读完 (大约 7149 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/04/YOLO3%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 数据处理与数据加载 Keras源码分析</a></h1><div class="content"><p>YOLO3 Keras 源码：<a href="https://github.com/qqwweee/keras-yolo3">https://github.com/qqwweee/keras-yolo3</a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文从主要是从源码层面对 YOLO3 的数据处理相关内容进行分析与讲解。通常，一个功能的实现需要多个函数配合，所以我将每个功能的实现函数分为两部分，<strong>基础函数</strong> 和 <strong>实现函数</strong> ：</p>
<ul>
<li>基础函数：被实现函数所依赖，是实现函数的一部分</li>
<li>实现函数：通过调用基础函数实现功能</li>
</ul>
<p>源码内容比较多，通过目录索引看感兴趣的地方即可。</p>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><h3 id="数据集转换"><a href="#数据集转换" class="headerlink" title="数据集转换"></a>数据集转换</h3><p>YOLO3 Keras 源码所需要的数据集应该在一个<code>.txt</code> ( 文本文件 )内，文件中的一行代表一个张图片和它的标签，其中每行的格式为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><code class="hljs plain">image_file_path box1 box2 ... boxN<br></code></pre></td></tr></table></figure>
<p><code>box*</code> 是该图片的标签，即真实框，不同box之间用空格隔开，其中每个box的格式为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><code class="hljs plain">x_min,y_min,x_max,y_max,class_id<br></code></pre></td></tr></table></figure>
<p>所以总的来说，训练用的数据集应该大体是这个样子的：</p></div><a class="article-more button is-small size-small" href="/2020/04/04/YOLO3%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-04T10:37:51.338Z" title="2020-04-04T10:37:51.338Z">2020-04-04</time><span class="level-item"><a class="link-muted" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 源码分析</a></span><span class="level-item">40 分钟 读完 (大约 5980 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/04/YOLO3%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 目标检测与性能评价 Keras源码分析</a></h1><div class="content"><h2 id="使用-YOLO3"><a href="#使用-YOLO3" class="headerlink" title="使用 YOLO3"></a>使用 YOLO3</h2><h3 id="配置-yolo-py"><a href="#配置-yolo-py" class="headerlink" title="配置 yolo.py"></a>配置 yolo.py</h3><p>修改 <code>yolo.py</code> 的 <code>_defaults</code>，主要是把自己训练好的权重文件路径、锚框文件路径、类别文件路径配置上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">_defaults = &#123;<br>      <span class="hljs-string">"model_path"</span>: <span class="hljs-string">'trained_weights_final.h5'</span>,<br>      <span class="hljs-string">"anchors_path"</span>: <span class="hljs-string">'yolo_anchors.txt'</span>,<br>      <span class="hljs-string">"classes_path"</span>: <span class="hljs-string">'voc_classes.txt'</span>,<br>      <span class="hljs-string">"score"</span> : <span class="hljs-number">0.3</span>,<br>      <span class="hljs-string">"iou"</span> : <span class="hljs-number">0.45</span>,<br>      <span class="hljs-string">"model_image_size"</span> : (<span class="hljs-number">416</span>, <span class="hljs-number">416</span>),<br>      <span class="hljs-string">"gpu_num"</span> : <span class="hljs-number">1</span>,<br>  &#125;<br></code></pre></td></tr></table></figure>
<h3 id="运行-yolo-video-py"><a href="#运行-yolo-video-py" class="headerlink" title="运行 yolo_video.py"></a>运行 yolo_video.py</h3><p><code>python yolo_video.py --image</code> 对单张图片进行测试，<code>python yolo_video.py --video</code> 对视频进行测试。</p></div><a class="article-more button is-small size-small" href="/2020/04/04/YOLO3%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%80%A7%E8%83%BD%E8%AF%84%E4%BB%B7%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/#more">阅读更多</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="" src="/img/avatar.png" alt="刘之帅"></figure><p class="title is-size-4 is-block line-height-inherit">刘之帅</p><p class="is-size-6 is-block">lzs783@qq.com</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>LiaoNing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">9</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/LogicForeach/" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/LogicForeach/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Web" href="https://logicforeach.net"><i class="fab fa-internet-explorer"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://blog.csdn.net/lzs781" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">CSDN</span></span><span class="level-right"><span class="level-item tag">blog.csdn.net</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">YOLO3 源码分析</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%B0%88/"><span class="level-start"><span class="level-item">机器学习杂谈</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-16T05:05:31.258Z">2020-04-16</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/16/%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%A4%9A%E7%BB%B4%E5%BC%A0%E9%87%8F%E7%9A%84reshape/">直观理解多维张量的reshape</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-14T07:44:30.084Z">2020-04-14</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">目标检测中的损失函数笔记整理(待续)</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-05T14:03:31.957Z">2020-04-05</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/05/%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E7%9A%84%E7%90%86%E8%A7%A3/">关于矩阵求导的理解</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%B0%88/">机器学习杂谈</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-05T13:53:29.833Z">2020-04-05</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83/">机器学习中的“分布”</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-04-04T11:00:09.966Z">2020-04-04</time></p><p class="title is-6"><a class="link-muted" href="/2020/04/04/YOLO3%20%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%20Keras%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 参数学习 Keras源码分析</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/YOLO3-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">YOLO3 源码分析</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">四月 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Keras/"><span class="tag">Keras</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YOLO3/"><span class="tag">YOLO3</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E7%BB%B4%E5%BC%A0%E9%87%8F/"><span class="tag">多维张量</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"><span class="tag">损失函数</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/"><span class="tag">概率分布</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="tag">目标检测</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC/"><span class="tag">矩阵求导</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/LOGO.jpg" alt="LogicForeach" height="28"></a><p class="size-small"><span>&copy; 2020 刘之帅</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>  <img src="https://static.dy208.cn/o_1dfilp8ruo521thr1hvf18ji17soa.png"><a href="http://beian.miit.gov.cn" style="color:#f72b07" target="_blank">辽ICP备17015584号</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'logicforeach.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script>window.addEventListener("load", function () {
            MathJax.Hub.Config({
                'HTML-CSS': {
                    matchFontHeight: false
                },
                SVG: {
                    matchFontHeight: false
                },
                CommonHTML: {
                    matchFontHeight: false
                },
                tex2jax: {
                    inlineMath: [
                        ['$','$'],
                        ['\\(','\\)']
                    ]
                }
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>